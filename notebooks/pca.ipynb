{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0345d3",
   "metadata": {},
   "source": [
    "# PCA for NSL-KDD\n",
    "\n",
    "Dimensionality reduction pipeline that feeds later anomaly detection steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc011cf",
   "metadata": {},
   "source": [
    "## Imports and plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd870db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2c2c7",
   "metadata": {},
   "source": "## Load preprocessed datasets\nLoad encoded/transformed data from preprocessing (not yet normalized)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_DIR / 'preproc_kdd_train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'preproc_kdd_test.csv')\n",
    "\n",
    "print(f'Train: {train_df.shape} | Test: {test_df.shape}')\n",
    "print(f'\\nAttack distribution (top 5):')\n",
    "print('TRAIN:', train_df['attack_type'].value_counts().head().to_dict())\n",
    "print('TEST: ', test_df['attack_type'].value_counts().head().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3f6202",
   "metadata": {},
   "source": [
    "## Scale features\n",
    "Normalize all numeric features except one-hot encoded columns (protocol_tcp, protocol_udp stay binary 0/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude one-hot columns from normalization (keep as binary 0/1)\n",
    "onehot_cols = ['protocol_tcp', 'protocol_udp']\n",
    "all_numeric = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "features_to_scale = [col for col in all_numeric if col not in onehot_cols and col != 'attack_type']\n",
    "\n",
    "# Fit scaler on training data\n",
    "scaler = StandardScaler()\n",
    "train_df[features_to_scale] = scaler.fit_transform(train_df[features_to_scale])\n",
    "test_df[features_to_scale] = scaler.transform(test_df[features_to_scale])\n",
    "\n",
    "print(f\"Normalized {len(features_to_scale)} features (excluded one-hot columns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a817f",
   "metadata": {},
   "source": [
    "## Extract features and labels\n",
    "Separate features from labels and convert attack_type to binary attack_flag (0=normal, 1=attack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b509b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (drop attack_type column)\n",
    "X_train = train_df.drop(columns='attack_type').to_numpy()\n",
    "X_test = test_df.drop(columns='attack_type').to_numpy()\n",
    "\n",
    "# Convert attack_type to binary: 0=normal, 1=attack\n",
    "y_train = (train_df['attack_type'] != 'normal').astype(int)\n",
    "y_test = (test_df['attack_type'] != 'normal').astype(int)\n",
    "\n",
    "print(f'Features: {X_train.shape} (train), {X_test.shape} (test)')\n",
    "print(f'Attack rate: {y_train.mean():.2%} (train), {y_test.mean():.2%} (test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5608e",
   "metadata": {},
   "source": [
    "## Determine optimal components\n",
    "Fit PCA and find number of components needed for 95% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3140528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit full PCA and compute cumulative variance\n",
    "pca_full = PCA().fit(X_train)\n",
    "cum_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "n_components_95 = int(np.argmax(cum_var >= 0.95) + 1)\n",
    "\n",
    "# Plot variance curve\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(range(1, len(cum_var) + 1), cum_var, marker='o')\n",
    "ax.axhline(0.95, color='r', linestyle='--', label='95% target')\n",
    "ax.axvline(n_components_95, color='g', linestyle='--', label=f'{n_components_95} components')\n",
    "ax.set_xlabel('Number of components')\n",
    "ax.set_ylabel('Cumulative variance explained')\n",
    "ax.set_title('PCA Variance Analysis')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Components for 95% variance: {n_components_95}')"
   ]
  },
  {
   "cell_type": "code",
   "id": "3yq4zk3sppt",
   "source": "# Fit PCA with optimal components and transform both datasets\npca = PCA(n_components=n_components_95, random_state=RANDOM_STATE)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Helper function to create PCA dataframe with attack_flag\ndef create_pca_df(X_pca, y):\n    cols = [f'pc{i:02d}' for i in range(1, X_pca.shape[1] + 1)]\n    df = pd.DataFrame(X_pca, columns=cols)\n    df['attack_flag'] = y.to_numpy()\n    return df\n\n# Create and save dataframes\ntrain_pca_df = create_pca_df(X_train_pca, y_train)\ntest_pca_df = create_pca_df(X_test_pca, y_test)\n\ntrain_pca_df.to_csv(DATA_DIR / 'PCA-nsl_kdd_train.csv', index=False)\ntest_pca_df.to_csv(DATA_DIR / 'PCA-nsl_kdd_test.csv', index=False)\n\nprint(f'Saved train: {train_pca_df.shape} -> {DATA_DIR / \"PCA-nsl_kdd_train.csv\"}')\nprint(f'Saved test:  {test_pca_df.shape} -> {DATA_DIR / \"PCA-nsl_kdd_test.csv\"}')\nprint(f'Columns: {list(train_pca_df.columns)}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1142q7qp93zs",
   "source": "## Apply PCA and save datasets\nTransform data and save as [pc01, pc02, ..., pcN, attack_flag].",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}