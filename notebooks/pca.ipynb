{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0345d3",
   "metadata": {},
   "source": [
    "# PCA for NSL-KDD\n",
    "\n",
    "Dimensionality reduction pipeline that feeds later anomaly detection steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc011cf",
   "metadata": {},
   "source": [
    "## Imports and plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd870db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2c2c7",
   "metadata": {},
   "source": [
    "## Load preprocessed datasets\n",
    "Use the normalized tables from the preprocessing notebook as the starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670b799",
   "metadata": {},
   "outputs": [],
   "source": "train_df = pd.read_csv(DATA_DIR / 'preproc_kdd_train.csv')\ntest_df = pd.read_csv(DATA_DIR / 'preproc_kdd_test.csv')\n\nprint(f'Train: {train_df.shape} | Test: {test_df.shape}')\nprint(f'\\nAttack distribution (top 5):')\nprint('TRAIN:', train_df['attack_type'].value_counts().head().to_dict())\nprint('TEST: ', test_df['attack_type'].value_counts().head().to_dict())"
  },
  {
   "cell_type": "markdown",
   "id": "da3f6202",
   "metadata": {},
   "source": "## Extract features and labels\nSeparate features from labels and convert attack_type to binary attack_flag (0=normal, 1=attack)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d8a54",
   "metadata": {},
   "outputs": [],
   "source": "# Extract features (drop attack_type column)\nX_train = train_df.drop(columns='attack_type').to_numpy()\nX_test = test_df.drop(columns='attack_type').to_numpy()\n\n# Convert attack_type to binary: 0=normal, 1=attack\ny_train = (train_df['attack_type'] != 'normal').astype(int)\ny_test = (test_df['attack_type'] != 'normal').astype(int)\n\nprint(f'Features: {X_train.shape} (train), {X_test.shape} (test)')\nprint(f'Attack rate: {y_train.mean():.2%} (train), {y_test.mean():.2%} (test)')"
  },
  {
   "cell_type": "markdown",
   "id": "d69a817f",
   "metadata": {},
   "source": "## Determine optimal components\nFit PCA and find number of components needed for 95% variance."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b509b7",
   "metadata": {},
   "outputs": [],
   "source": "# Fit full PCA and compute cumulative variance\npca_full = PCA().fit(X_train)\ncum_var = np.cumsum(pca_full.explained_variance_ratio_)\nn_components_95 = int(np.argmax(cum_var >= 0.95) + 1)\n\n# Plot variance curve\nfig, ax = plt.subplots(figsize=(10, 5))\nax.plot(range(1, len(cum_var) + 1), cum_var, marker='o')\nax.axhline(0.95, color='r', linestyle='--', label='95% target')\nax.axvline(n_components_95, color='g', linestyle='--', label=f'{n_components_95} components')\nax.set_xlabel('Number of components')\nax.set_ylabel('Cumulative variance explained')\nax.set_title('PCA Variance Analysis')\nax.legend()\nplt.show()\n\nprint(f'Components for 95% variance: {n_components_95}')"
  },
  {
   "cell_type": "markdown",
   "id": "faf5608e",
   "metadata": {},
   "source": "## Apply PCA and save datasets\nTransform data and save as [pc01, pc02, ..., pcN, attack_flag]."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3140528",
   "metadata": {},
   "outputs": [],
   "source": "# Fit PCA with optimal components and transform both datasets\npca = PCA(n_components=n_components_95, random_state=RANDOM_STATE)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Helper function to create PCA dataframe with attack_flag\ndef create_pca_df(X_pca, y):\n    cols = [f'pc{i:02d}' for i in range(1, X_pca.shape[1] + 1)]\n    df = pd.DataFrame(X_pca, columns=cols)\n    df['attack_flag'] = y.to_numpy()\n    return df\n\n# Create and save dataframes\ntrain_pca_df = create_pca_df(X_train_pca, y_train)\ntest_pca_df = create_pca_df(X_test_pca, y_test)\n\ntrain_pca_df.to_csv(DATA_DIR / 'PCA-nsl_kdd_train.csv', index=False)\ntest_pca_df.to_csv(DATA_DIR / 'PCA-nsl_kdd_test.csv', index=False)\n\nprint(f'Saved train: {train_pca_df.shape} -> {DATA_DIR / \"PCA-nsl_kdd_train.csv\"}')\nprint(f'Saved test:  {test_pca_df.shape} -> {DATA_DIR / \"PCA-nsl_kdd_test.csv\"}')\nprint(f'Columns: {list(train_pca_df.columns)}')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}